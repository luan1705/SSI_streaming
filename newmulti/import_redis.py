import redis
import pandas as pd
import json
from sqlalchemy import create_engine, text
from concurrent.futures import ThreadPoolExecutor, as_completed
import sys
import os

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from List.exchange import total_list

# K·∫øt n·ªëi DB
engine = create_engine('postgresql://vnsfintech:%40Vns123456@videv.cloud:5432/vnsfintech')

# K·∫øt n·ªëi Redis
REDIS_URL   = "redis://default:%40Vns123456@videv.cloud:6379/1"
POOL = redis.BlockingConnectionPool.from_url(
    REDIS_URL,
    decode_responses=True,
    socket_timeout=2.5,           # timeout ƒë·ªçc/ghi
    socket_connect_timeout=2.0,   # timeout connect
    health_check_interval=30,     # ping ƒë·ªãnh k·ª≥ 30s
    max_connections=30,            # M·ªói container ch·ªâ t·ªëi ƒëa 3 socket t·ªõi Redis
    timeout=1.0,                  # Khi pool b·∫≠n, ch·ªù t·ªëi ƒëa 1s ƒë·ªÉ l·∫•y connection (kh√¥ng drop)
)
r = redis.Redis(connection_pool=POOL)

# Danh s√°ch m√£
symbol_list = total_list
SCHEMA = "history_tradingview"

# H√†m l·∫•y d·ªØ li·ªáu t·ª´ PostgreSQL v√† l∆∞u v√†o Redis
def get_data_and_cache(symbol):
    query = text(f"""
        SELECT "time", "symbol", "open", "high", "low", "close", "volume"
        FROM "{SCHEMA}"."{symbol}_1D"
        WHERE "time"::date != CURRENT_DATE
        ORDER BY time DESC
        LIMIT 200
    """)
    try:
        df = pd.read_sql(query, con=engine)
        if not df.empty:
            df = df.sort_values('time', ascending=True).reset_index(drop=True)
            redis_list = [
                json.dumps({
                    "time": row["time"].strftime("%Y-%m-%d %H:%M:%S"),
                    "symbol": row["symbol"],
                    "open": row["open"],
                    "high": row["high"],
                    "low": row["low"],
                    "close": row["close"],
                    "volume": row["volume"]
                }) for _, row in df.iterrows()
            ]
            redis_key = f"{SCHEMA}:{symbol}"
            r.delete(redis_key)
            r.rpush(redis_key, *redis_list)
            print(f"‚úÖ ƒê√£ l∆∞u Redis: {symbol}")
            return symbol
        else:
            print(f"‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu: {symbol}")
    except Exception as e:
        print(f"L·ªói {symbol}:{e}")
    return None

# H√†m ch·∫°y ƒëa lu·ªìng
def run_multithreaded_cache():
    with ThreadPoolExecutor(max_workers=20) as executor:
        futures = [executor.submit(get_data_and_cache, symbol) for symbol in symbol_list]

        for future in as_completed(futures):
            _ = future.result()  # C√≥ th·ªÉ x·ª≠ l√Ω k·∫øt qu·∫£ n·∫øu c·∫ßn

# Ch·∫°y ch√≠nh
if __name__ == "__main__":
    print(f"üöÄ B·∫Øt ƒë·∫ßu l∆∞u d·ªØ li·ªáu Redis cho {len(symbol_list)} m√£...")
    run_multithreaded_cache()
    print("‚úÖ Ho√†n t·∫•t l∆∞u Redis.")

